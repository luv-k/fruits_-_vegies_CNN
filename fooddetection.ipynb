{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1739262998382,
     "user": {
      "displayName": "Lavish",
      "userId": "09289804181169933579"
     },
     "user_tz": -330
    },
    "id": "Rgd-U0ERhANU",
    "outputId": "39c7318a-35b6-485f-8b71-2a53105d4b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "print(\"Imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739263000435,
     "user": {
      "displayName": "Lavish",
      "userId": "09289804181169933579"
     },
     "user_tz": -330
    },
    "id": "donLZ0TLfv4D",
    "outputId": "d5fb29ed-ceaa-4730-8903-8cc81d767a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Cnxehl33p8h"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"fruits and vegies\\\\archive (1)\"\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=f\"{data_dir}\\\\train\", transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=f\"{data_dir}\\\\test\", transform=transform_test)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=f\"{data_dir}\\\\validation\", transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 46187\n",
      "Validation samples: 12544\n",
      "Test samples: 13353\n",
      "Classes: ['Apple', 'Avocado', 'Banana', 'Beetroot', 'Blackberry', 'Blueberry', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Chilli Peper', 'Corn', 'Cucumber', 'Dates', 'Dragonfruit', 'Eggplant', 'Fig', 'Garlic', 'Ginger', 'Grapes', 'Guava', 'Jalepeno', 'Kiwi', 'Lemon', 'Lettuce', 'Mango', 'Mushroom', 'Okra', 'Olive', 'Onion', 'Orange', 'Paprika', 'Peanuts', 'Pear', 'Peas', 'Pineapple', 'Pomegranate', 'Potato', 'Pumpkin', 'Raddish', 'Rambutan', 'Soy Beans', 'Spinach', 'Strawberry', 'Sweetcorn', 'Sweetpotato', 'Tomato', 'Turnip', 'Watermelon']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Validation samples:\", len(val_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))\n",
    "print(\"Classes:\", train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "error",
     "timestamp": 1739263043370,
     "user": {
      "displayName": "Lavish",
      "userId": "09289804181169933579"
     },
     "user_tz": -330
    },
    "id": "1JLVfDzN4CKe",
    "outputId": "c9c96a60-889c-49d7-83ab-07e65d69ec90"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers = 4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers = 4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "N1xaEyyTCuW7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'Avocado',\n",
       " 'Banana',\n",
       " 'Beetroot',\n",
       " 'Blackberry',\n",
       " 'Blueberry',\n",
       " 'Broccoli',\n",
       " 'Cabbage',\n",
       " 'Capsicum',\n",
       " 'Carrot',\n",
       " 'Cauliflower',\n",
       " 'Chilli Peper',\n",
       " 'Corn',\n",
       " 'Cucumber',\n",
       " 'Dates',\n",
       " 'Dragonfruit',\n",
       " 'Eggplant',\n",
       " 'Fig',\n",
       " 'Garlic',\n",
       " 'Ginger',\n",
       " 'Grapes',\n",
       " 'Guava',\n",
       " 'Jalepeno',\n",
       " 'Kiwi',\n",
       " 'Lemon',\n",
       " 'Lettuce',\n",
       " 'Mango',\n",
       " 'Mushroom',\n",
       " 'Okra',\n",
       " 'Olive',\n",
       " 'Onion',\n",
       " 'Orange',\n",
       " 'Paprika',\n",
       " 'Peanuts',\n",
       " 'Pear',\n",
       " 'Peas',\n",
       " 'Pineapple',\n",
       " 'Pomegranate',\n",
       " 'Potato',\n",
       " 'Pumpkin',\n",
       " 'Raddish',\n",
       " 'Rambutan',\n",
       " 'Soy Beans',\n",
       " 'Spinach',\n",
       " 'Strawberry',\n",
       " 'Sweetcorn',\n",
       " 'Sweetpotato',\n",
       " 'Tomato',\n",
       " 'Turnip',\n",
       " 'Watermelon']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class netCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(netCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Adaptive Pooling â†’ output size 4x4 (can be adjusted)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolution + BatchNorm + ReLU + Pool\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 32 x 112 x 112\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # 64 x 56 x 56\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # 128 x 28 x 28\n",
    "        \n",
    "        # Adaptive Pooling â†’ 128 x 4 x 4\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = netCNN(num_classes=len(class_names)).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "num_epochs = 20\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ------------------ TRAIN ------------------\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # ------------------ VALIDATION ------------------\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(net.state_dict(), \"best_model.pth\")\n",
    "        print(f\"ðŸ”¥ Saved new BEST model (Acc={best_acc:.2f}%)\")\n",
    "\n",
    "    # update LR\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(f\"Best validation accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "net.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct_test / total_test\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=================================\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, preds = outputs.max(1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ---------------------- EXPORT TO ONNX -----------------------\n",
    "# =============================================================\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 128, 128).to(device)\n",
    "torch.onnx.export(\n",
    "    net,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "print(\"\\nModel exported to model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMu4yW4kttw/42qCQJpyo3V",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
